{
    "cells": [
     {
      "cell_type": "markdown",
      "id": "bcf1d6e3-ff37-47f5-bd49-35f9e11218a0",
      "metadata": {},
      "source": [
       "# Data Preprocessing and Modeling Notebook\n",
       "\n",
       "This notebook demonstrates our complete workflow: cleaning a dataset from outliers, splitting and standardizing the data (without data leakage), and finally training a linear classifier. Our custom functions from `functions.py` are used throughout."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "83b4e8e1-72f0-40a5-91b3-313ea3d896bb",
      "metadata": {},
      "outputs": [],
      "source": [
       "import numpy as np\n",
       "import pandas as pd\n",
       "import matplotlib.pyplot as plt\n",
       "\n",
       "# Import our custom functions and classes\n",
       "from functions import (\n",
       "    to_pm1_labels,\n",
       "    remove_outliers_from_file,\n",
       "    split_and_standardize_data,\n",
       "    Perceptron\n",
       "    # (other functions/classes are available as well)\n",
       ")\n",
       "\n",
       "%matplotlib inline"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f5e33a2-1f10-4d08-97c8-d3e6a02d3380",
      "metadata": {},
      "outputs": [],
      "source": [
       "# ------------------------------\n",
       "# Create a synthetic dataset\n",
       "# ------------------------------\n",
       "\n",
       "np.random.seed(42)\n",
       "n_samples = 200\n",
       "\n",
       "# Generate two features from a standard normal distribution\n",
       "X = np.random.randn(n_samples, 2)\n",
       "\n",
       "# Create labels based on a linear decision boundary through the origin\n",
       "# (e.g. label = 1 if x1 + x2 > 0, else 0)\n",
       "y = (X[:, 0] + X[:, 1] > 0).astype(int)\n",
       "\n",
       "# Introduce some outliers manually\n",
       "n_outliers = 5\n",
       "outliers = np.array([[10, 10], [10, 9.5], [9.5, 10], [-10, -10], [-9.5, -10]])\n",
       "outlier_labels = np.array([1, 1, 1, 0, 0])\n",
       "\n",
       "# Append the outliers\n",
       "X_all = np.vstack([X, outliers])\n",
       "y_all = np.concatenate([y, outlier_labels])\n",
       "\n",
       "# Create a DataFrame and save to CSV\n",
       "df = pd.DataFrame(X_all, columns=[\"feature1\", \"feature2\"])\n",
       "df[\"label\"] = y_all\n",
       "csv_file = \"data.csv\"\n",
       "df.to_csv(csv_file, index=False)\n",
       "\n",
       "print(f\"Dataset created with {X_all.shape[0]} samples (including {n_outliers} outliers) and saved to {csv_file}.\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eb5070c-30fa-4d3b-8a3e-dc59df0a5a9a",
      "metadata": {},
      "outputs": [],
      "source": [
       "# ------------------------------\n",
       "# Remove outliers from the CSV file\n",
       "# ------------------------------\n",
       "\n",
       "# Remove outliers based on z-score for 'feature1' and 'feature2'\n",
       "remove_outliers_from_file(csv_file, threshold=3.0, columns=[\"feature1\", \"feature2\"])"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d9136a4-0dd4-4a59-9d28-54ad74c86c42",
      "metadata": {},
      "outputs": [],
      "source": [
       "# ------------------------------\n",
       "# Load and inspect the cleaned data\n",
       "# ------------------------------\n",
       "\n",
       "df_clean = pd.read_csv(csv_file)\n",
       "print(\"Cleaned dataset shape:\", df_clean.shape)\n",
       "df_clean.head()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bbfd8e7-4d90-4f44-8b2f-b60a1732e5e2",
      "metadata": {},
      "outputs": [],
      "source": [
       "# ------------------------------\n",
       "# Preprocess the data\n",
       "# ------------------------------\n",
       "\n",
       "# Separate features and label\n",
       "X = df_clean[[\"feature1\", \"feature2\"]].values\n",
       "y = df_clean[\"label\"].values\n",
       "\n",
       "# Convert labels to {-1, +1} if necessary\n",
       "y = to_pm1_labels(y)\n",
       "\n",
       "# Split and standardize the data\n",
       "X_train, X_test, y_train, y_test = split_and_standardize_data(X, y, test_ratio=0.2, random_state=42)\n",
       "\n",
       "print(f\"Training set: {X_train.shape[0]} samples\")\n",
       "print(f\"Test set: {X_test.shape[0]} samples\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aa9e4a0-133b-47b3-b7f7-52a7296370f8",
      "metadata": {},
      "outputs": [],
      "source": [
       "# ------------------------------\n",
       "# Visualize the training and test sets\n",
       "# ------------------------------\n",
       "\n",
       "plt.figure(figsize=(8, 6))\n",
       "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='coolwarm', marker='o', label='Train')\n",
       "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap='coolwarm', marker='s', edgecolors='k', label='Test')\n",
       "plt.xlabel('Feature 1')\n",
       "plt.ylabel('Feature 2')\n",
       "plt.title('Training and Test Sets (Standardized)')\n",
       "plt.legend()\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "623ef7a3-3845-4f10-b2b3-4975d80b09bf",
      "metadata": {},
      "outputs": [],
      "source": [
       "# ------------------------------\n",
       "# Train a Perceptron model\n",
       "# ------------------------------\n",
       "\n",
       "model = Perceptron(max_iter=20, shuffle=True, random_state=42)\n",
       "model.fit(X_train, y_train)\n",
       "\n",
       "# Evaluate the model on the test set\n",
       "test_accuracy = model.score(X_test, y_test)\n",
       "print(f\"Test Accuracy of Perceptron: {test_accuracy * 100:.2f}%\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1a2a1b9-52bb-4d4a-b83c-9e6bd99e2a04",
      "metadata": {},
      "outputs": [],
      "source": [
       "# ------------------------------\n",
       "# Plot the decision boundary\n",
       "# ------------------------------\n",
       "\n",
       "# For a linear classifier in 2D (without explicit bias) the decision boundary is defined by:\n",
       "#    w1*x1 + w2*x2 = 0  =>  x2 = -(w1/w2)*x1\n",
       "\n",
       "w = model.w\n",
       "if np.abs(w[1]) > 1e-6:\n",
       "    x_vals = np.linspace(X_train[:, 0].min()-1, X_train[:, 0].max()+1, 100)\n",
       "    y_vals = -(w[0] * x_vals) / w[1]\n",
       "    \n",
       "    plt.figure(figsize=(8, 6))\n",
       "    \n",
       "    # Plot training and test points\n",
       "    plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='coolwarm', marker='o', label='Train')\n",
       "    plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap='coolwarm', marker='s', edgecolors='k', label='Test')\n",
       "    \n",
       "    # Plot decision boundary\n",
       "    plt.plot(x_vals, y_vals, 'k--', label='Decision Boundary')\n",
       "    plt.xlabel('Feature 1')\n",
       "    plt.ylabel('Feature 2')\n",
       "    plt.title('Perceptron Decision Boundary')\n",
       "    plt.legend()\n",
       "    plt.show()\n",
       "else:\n",
       "    print(\"Cannot plot decision boundary: w[1] is too close to zero.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "e46187f8-4b1e-4a68-b7c2-0e3b44a823d1",
      "metadata": {},
      "source": [
       "## Summary\n",
       "\n",
       "In this notebook we demonstrated how to preprocess a dataset by removing outliers, splitting and standardizing the data while avoiding data leakage, and finally training and visualizing a linear Perceptron classifier. You can extend this notebook by using other models from your code (e.g. PegasosSVM, KernelPerceptron) and by incorporating additional visualizations as needed."
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "name": "python",
      "version": "3.x"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 5
   }

